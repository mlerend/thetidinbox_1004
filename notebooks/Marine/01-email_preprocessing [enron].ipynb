{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYFlA7xMpKOB"
   },
   "source": [
    "# 01-email_preprocessing [enron]\n",
    "\n",
    "* __Status__ : OK\n",
    "* __Dataset__ : /thetidinbox_1004/notebooks/Marine/enron1.tar.gz [as an example]\n",
    "* __Source__ : Enron Email Dataset [https://www.cs.cmu.edu/~enron/]\n",
    "* __Labeled__ : Yes. Spam/Ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2OQ9sk5pKOE"
   },
   "source": [
    "## 📚 **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToO-JplYpKOF"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-Sb0zckpKOQ"
   },
   "outputs": [],
   "source": [
    "# enron1.tar.gz contains all the emails\n",
    "enron_files = 'enron1.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qweY0SHSpKOV"
   },
   "source": [
    "## Methodology :\n",
    "\n",
    "### Preparing the text data:\n",
    "\n",
    "1. **extract_emails(fname)** : This functions reads the tarfile and stores into a list. List has two columns 'Message' and 'Class'. Message contains extracted emails and Class has the category like 'ham' or 'spam'. The list is then converted into a dataframe and then returned. The argument passed here is the folder name. \n",
    "\n",
    "2. **populate_df()** : This function populates all the emails into a Dataframe. This function also drops rows having NA values and duplicate rows.This function returns a dataframe.\n",
    "\n",
    "3. **clean_email(email)** : This function removes all punctuation, urls, numbers, and newlines. Also converts it into lower case. Arguments passed here is the messages i.e. emails and returns same cleaned email.\n",
    "\n",
    "4. **preproces_email(email)** :  This function splits the text string into individual words, stem each word, and append the stemmed word to words. Make sure there's a single space between each stemmed word. Arguments passed here is the messages i.e. emails and returns the text of the email.\n",
    "\n",
    "5. **stopword_removal(email)** : This functions removes the stopwords left in the email text passed as argument and returns text without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NedXxY1dpKOW"
   },
   "outputs": [],
   "source": [
    "def extract_emails(fname):\n",
    "    \"\"\" Extract the zipped emails and load them into a pandas df \"\"\"\n",
    "\n",
    "    rows = []\n",
    "    # tarfiles are used to read and write tar archives\n",
    "    originalfile = tarfile.open(fname, 'r:gz')\n",
    "    for member in originalfile.getmembers():\n",
    "        if 'ham' in member.name:\n",
    "            f = originalfile.extractfile(member)\n",
    "            if f is not None:\n",
    "                row = f.read()\n",
    "                rows.append({'message': row, 'class': 'ham'}) \n",
    "        if 'spam' in member.name:\n",
    "            f = originalfile.extractfile(member)\n",
    "            if f is not None:\n",
    "                row = f.read()\n",
    "                rows.append({'message': row, 'class': 'spam'})\n",
    "    originalfile.close()\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbjZ2wx6pKOc"
   },
   "outputs": [],
   "source": [
    "def populate_df():\n",
    "    \"\"\" Populate the dataframe with all the emails \"\"\"\n",
    "\n",
    "    emails_df = pd.DataFrame({'message': [], 'class': []})\n",
    "\n",
    "    unzipped_file = extract_emails(enron_files)\n",
    "    emails_df = emails_df.append(unzipped_file)\n",
    "    print(\"The dimensions of Dataframe created after extracting the tarfile:\",emails_df.shape)\n",
    "    \n",
    "    # Dropping all the rows with NA values\n",
    "    emails_df.dropna()\n",
    "    # Dropping all the duplicates but keeping the first instance\n",
    "    emails_df.drop_duplicates(keep='first',inplace=True)\n",
    "    print(\"The dimensions of Dataframe after droping rows containing NA values and duplicates: \",emails_df.shape)\n",
    "    \n",
    "    return(emails_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TD-T5gdpKOj"
   },
   "outputs": [],
   "source": [
    "def clean_email(email):\n",
    "    \n",
    "    # Remove mentions\n",
    "    email = re.sub(r'@\\w+', '', email)\n",
    "    # Remove urls\n",
    "    email = re.sub(r'http\\S+', ' ', email)\n",
    "    # Remove digits\n",
    "    email = re.sub(\"\\d+\", \" \", email)\n",
    "    email = email.replace('\\n', ' ')\n",
    "    # Remove punctuations\n",
    "    email = email.translate(str.maketrans(\"\", \"\", punctuation))\n",
    "    email = email.lower()\n",
    "    \n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4hkD3sDpKOp"
   },
   "outputs": [],
   "source": [
    "def preproces_email(email):\n",
    "\n",
    "    words = \"\"\n",
    "    # Create the stemmer.\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    # Split text into words.\n",
    "    email = email.split()\n",
    "    for word in email:\n",
    "        # Optional: remove unknown words.\n",
    "        words = words + stemmer.stem(word) + \" \"\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_mA__2_pKOy"
   },
   "outputs": [],
   "source": [
    "def stopword_removal(email):\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    email = email.split()\n",
    "    filtered_sentence = \"\"\n",
    "\n",
    "    for w in email: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence = filtered_sentence + w +\" \"\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iojHhNHRpKO5"
   },
   "source": [
    "### Main Function :\n",
    "\n",
    "This function calls the above defined functions for cleaning the data and displays every functions output. Final text displayed is a clean text which will be further used for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znLLJz-JpKO6",
    "outputId": "5f9f482c-71f5-4edc-8e7a-ae17067b78cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/87n9sw2x5j5cbsyb3dw7_4mm0000gn/T/ipykernel_66110/3627688345.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  emails_df = emails_df.append(unzipped_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of Dataframe created after extracting the tarfile: (5172, 2)\n",
      "The dimensions of Dataframe after droping rows containing NA values and duplicates:  (4994, 2)\n",
      "Downloaded and unziped the files\n",
      "==================================================================================================================\n",
      "After mapping spam and ham emails to 1 and 0 respectively : \n",
      " ['Subject: txu fuel co . nom . s for 2 / 20 / 01\\r\\n( see attached file : hplno 220 . xls )\\r\\n- hplno 220 . xls'\n",
      " 0]\n",
      "==================================================================================================================\n",
      "After cleaning email : \n",
      " ['subject txu fuel co  nom  s for        \\r  see attached file  hplno    xls \\r  hplno    xls'\n",
      " 0]\n",
      "==================================================================================================================\n",
      "Removing the stopwords : \n",
      " ['subject txu fuel co nom see attached file hplno xls hplno xls ' 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    emails_df = populate_df()\n",
    "    print(\"Downloaded and unziped the files\")\n",
    "    print(\"==================================================================================================================\")\n",
    "    # Translate bytes objects into strings.\n",
    "    emails_df['message'] = emails_df['message'].apply(lambda x: x.decode('latin-1'))\n",
    "\n",
    "    # Reset pandas df index.\n",
    "    emails_df = emails_df.reset_index(drop=True)\n",
    "\n",
    "    # Map 'spam' to 1 and 'ham' to 0\n",
    "    emails_df['class'] = emails_df['class'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "    print(\"After mapping spam and ham emails to 1 and 0 respectively : \\n\",emails_df.iloc[2500].values)\n",
    "    print(\"==================================================================================================================\")\n",
    "    \n",
    "    emails_df['message'] = emails_df['message'].apply(clean_email)\n",
    "\n",
    "    print(\"After cleaning email : \\n\",emails_df.iloc[2500].values)\n",
    "    print(\"==================================================================================================================\")\n",
    "    \n",
    "    #emails_df['message'] = emails_df['message'].apply(preproces_email)\n",
    "    \n",
    "    #print(\"After preprocessing the texts : \\n\",emails_df.iloc[2500].values)\n",
    "    #print(\"==================================================================================================================\")\n",
    "    \n",
    "    emails_df['message'] = emails_df['message'].apply(stopword_removal)\n",
    "    \n",
    "    print(\"Removing the stopwords : \\n\",emails_df.iloc[2500].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject christmas tree farm pictures</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject vastar resources inc gary production h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject calpine daily gas nomination calpine d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject issue fyi see note already done stella...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject meter nov allocation fyi forwarded lau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>subject pro forma invoice attached divide cove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>subject str rndlen extra time word bodyhtml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>subject check bb hey derm bbbbb check paris ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>subject hot jobs global marketing specialties ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>subject save ink shipping cost save inkjet las...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4994 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  class\n",
       "0                 subject christmas tree farm pictures       0\n",
       "1     subject vastar resources inc gary production h...      0\n",
       "2     subject calpine daily gas nomination calpine d...      0\n",
       "3     subject issue fyi see note already done stella...      0\n",
       "4     subject meter nov allocation fyi forwarded lau...      0\n",
       "...                                                 ...    ...\n",
       "4989  subject pro forma invoice attached divide cove...      1\n",
       "4990       subject str rndlen extra time word bodyhtml       1\n",
       "4991  subject check bb hey derm bbbbb check paris ma...      1\n",
       "4992  subject hot jobs global marketing specialties ...      1\n",
       "4993  subject save ink shipping cost save inkjet las...      1\n",
       "\n",
       "[4994 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df.to_csv('email_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Email Preprocessing functions done ✅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Let's jump to the Spam/Ham classifier notebook [/thetidinbox_1004/notebooks/Marine/02-email_spam_classification_[enron].ipynb]\n",
    "\n",
    "🚨 **To do:** transfer these functions to a .py file at the end of the project."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Spam n Ham Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
