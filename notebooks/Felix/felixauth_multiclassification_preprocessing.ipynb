{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab61f0b4",
   "metadata": {},
   "source": [
    "# Emails_multiclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3d31b",
   "metadata": {},
   "source": [
    "## Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b128cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79788553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "import mailparser\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "sys.path.insert(0, '/home/felix/code/mlerend/thetidinbox_1004/thetidinbox_1004')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9c228",
   "metadata": {},
   "source": [
    "## Import of labeled emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f90f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = pd.DataFrame({\"message\" : [],\n",
    "                         \"category\" : []})\n",
    "for i in range(1,9):\n",
    "    path_data = f'../../raw_data/enron/emails/txt_files_categories/all_txt_files{i}.txt'\n",
    "    with open(path_data) as f:\n",
    "        contents = f.read()\n",
    "        emails_cat = [\"Message-ID: \" + email for email in contents.split(\"Message-ID: \") if email]\n",
    "        emails_df = pd.concat([emails_df, pd.DataFrame({\"message\" : emails_cat,\n",
    "                         \"category\" : int(i)})]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67717222",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_gh = pd.read_csv('https://raw.githubusercontent.com/brindasachi97/Enron-Email-Classification/master/combinedDS.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ee151",
   "metadata": {},
   "source": [
    "## Import of sample of non-labeled emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40df52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_sample_df = pd.read_csv(\"../../raw_data/enron/emails.csv\", nrows = 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabb428",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d508ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(email):\n",
    "    mail = mailparser.parse_from_string(email)\n",
    "    date = mail.date\n",
    "    return date\n",
    "\n",
    "def extract_sender(email):\n",
    "    mail = mailparser.parse_from_string(email)\n",
    "    if len(mail.from_) > 0:\n",
    "        sender = mail.from_[0][1]\n",
    "    else:\n",
    "        sender = mail.from_\n",
    "    return sender\n",
    "\n",
    "def extract_recipients(email):\n",
    "    mail = mailparser.parse_from_string(email)\n",
    "    if len(mail.to) > 0:\n",
    "        to = \",\".join([rec[1] for rec in mail.to])\n",
    "    else:\n",
    "        to = mail.to\n",
    "    return to\n",
    "\n",
    "def extract_header(email):\n",
    "    mail = mailparser.parse_from_string(email)\n",
    "    header = mail.subject\n",
    "    return header\n",
    "\n",
    "def extract_body(email, failure=\"\", *exceptions):\n",
    "    try:\n",
    "        mail = mailparser.parse_from_string(email)\n",
    "        body = mail.body\n",
    "    except exceptions or Exception:\n",
    "        return failure\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ebaac1",
   "metadata": {},
   "source": [
    "### Parsing labeled emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "829e0a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Email content 'mixed' not handled\n",
      "Email content 'mixed' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'alternative' not handled\n",
      "Email content 'mixed' not handled\n",
      "Email content 'mixed' not handled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197504</td>\n",
       "      <td>---------------------- Forwarded by Steven J K...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11991339</td>\n",
       "      <td>In anticipation of potential litigation involv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7106753</td>\n",
       "      <td>Julia and Steve--here are some questions I've ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21267718</td>\n",
       "      <td>Julia and Steve--here are some questions I've ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20866019</td>\n",
       "      <td>In anticipation of potential litigation involv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               body  category\n",
       "0    197504  ---------------------- Forwarded by Steven J K...       1.0\n",
       "1  11991339  In anticipation of potential litigation involv...       1.0\n",
       "2   7106753  Julia and Steve--here are some questions I've ...       1.0\n",
       "3  21267718  Julia and Steve--here are some questions I've ...       1.0\n",
       "4  20866019  In anticipation of potential litigation involv...       1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_parsed = pd.DataFrame()\n",
    "emails_df_parsed[\"ID\"] = emails_df[\"message\"].apply(lambda x: re.search(r'\\d+',x)[0])\n",
    "# emails_df_parsed[\"date\"] = emails_df[\"message\"].apply(extract_date)\n",
    "# emails_df_parsed[\"from\"] = emails_df[\"message\"].apply(extract_sender)\n",
    "# emails_df_parsed[\"to\"] = emails_df[\"message\"].apply(extract_recipients)\n",
    "# emails_df_parsed[\"header\"] = emails_df[\"message\"].apply(extract_header)\n",
    "emails_df_parsed[\"body\"] = emails_df[\"message\"].apply(extract_body)\n",
    "emails_df_parsed[\"category\"] = emails_df[\"category\"]\n",
    "emails_df_parsed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf436624",
   "metadata": {},
   "source": [
    "### Parsing non-labeled emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51f58996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18782981</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15464986</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24216240</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13505866</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30922949</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               body  category\n",
       "0  18782981                          Here is our forecast\\n\\n         -1\n",
       "1  15464986  Traveling to have a business meeting takes the...        -1\n",
       "2  24216240                     test successful.  way to go!!!        -1\n",
       "3  13505866  Randy,\\n\\n Can you send me a schedule of the s...        -1\n",
       "4  30922949                Let's shoot for Tuesday at 11:45.          -1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_sample_df_parsed = pd.DataFrame()\n",
    "emails_sample_df_parsed[\"ID\"] = emails_sample_df[\"message\"].apply(lambda x: re.search(r'\\d+',x)[0])\n",
    "# emails_sample_df_parsed[\"date\"] = emails_sample_df[\"message\"].apply(extract_date)\n",
    "# emails_sample_df_parsed[\"from\"] = emails_sample_df[\"message\"].apply(extract_sender)\n",
    "# emails_sample_df_parsed[\"to\"] = emails_sample_df[\"message\"].apply(extract_recipients)\n",
    "# emails_sample_df_parsed[\"header\"] = emails_sample_df[\"message\"].apply(extract_header)\n",
    "emails_sample_df_parsed[\"body\"] = emails_sample_df[\"message\"].apply(extract_body)\n",
    "emails_sample_df_parsed[\"category\"] = -1\n",
    "emails_sample_df_parsed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd72c4d",
   "metadata": {},
   "source": [
    "## Concatenating the labeled and non-labeled emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88159a",
   "metadata": {},
   "source": [
    "### Removing potential labeled emails in the non-labeled emails sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14a55a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19981, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_labeled = emails_df_parsed.ID.unique()\n",
    "ID_non_labeled = emails_sample_df_parsed.ID.unique()\n",
    "ID_to_delete = []\n",
    "for id_email in ID_labeled:\n",
    "    if id_email in ID_non_labeled:\n",
    "        ID_to_delete.append(id_email)\n",
    "emails_sample_df_parsed = emails_sample_df_parsed[~emails_sample_df_parsed[\"ID\"].isin(ID_to_delete)]\n",
    "emails_sample_df_parsed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201bbd2",
   "metadata": {},
   "source": [
    "### Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "454e7b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21697, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_all = pd.concat([emails_df_parsed,emails_sample_df_parsed], axis=0).reset_index(drop=True)\n",
    "emails_df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d960024",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed5d52c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of emails</th>\n",
       "      <th>% of total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>839.0</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>1716.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number of emails  % of total\n",
       "1.0               839.0        0.49\n",
       "2.0                38.0        0.02\n",
       "3.0               102.0        0.06\n",
       "4.0               480.0        0.28\n",
       "5.0                74.0        0.04\n",
       "6.0               144.0        0.08\n",
       "7.0                21.0        0.01\n",
       "8.0                18.0        0.01\n",
       "Total            1716.0        0.99"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_email_per_cat = emails_df_all[emails_df_all[\"category\"]!=-1][\"category\"].value_counts().sort_index()\n",
    "weight_email_per_cat = emails_df_all[emails_df_all[\"category\"]!=-1][\"category\"].value_counts(normalize=True).sort_index()\n",
    "num_mail_df = pd.DataFrame({\"number of emails\" : num_email_per_cat.values,\n",
    "             \"% of total\" : round(weight_email_per_cat,2)}, index = num_email_per_cat.index)\n",
    "num_mail_df.loc[\"Total\"] = num_mail_df.sum()\n",
    "num_mail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4496b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre moyen de mots par email est de 2264\n"
     ]
    }
   ],
   "source": [
    "avg_length = int(emails_df_all[\"body\"].apply(lambda x : len(x)).mean())\n",
    "print(f\"Le nombre moyen de mots par email est de {avg_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33ca0462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(emails_df_all[\"body\"].apply(lambda x : len(x)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b862a39",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6de0bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(email):\n",
    "\n",
    "    # Remove mentions\n",
    "    email = re.sub(r'@\\w+', '', email)\n",
    "    # Remove urls\n",
    "    email = re.sub(r'http\\S+', ' ', email)\n",
    "    # Remove digits\n",
    "    email = re.sub(\"\\d+\", \" \", email)\n",
    "    # Remove backline character\n",
    "    email = email.replace('\\n', ' ')\n",
    "    # Remove forwarded emails\n",
    "#     email = re.sub(\"Forwarded by.*$\",' ', email)\n",
    "#     email = re.sub(\"Original Message.*$\",' ', email)\n",
    "    \n",
    "    # Remove digits between brackets\n",
    "    email = re.sub(r'<.*>', '', email)\n",
    "    # Remove punctuations\n",
    "    email = email.translate(str.maketrans(\" \", \" \", punctuation))\n",
    "    email = email.lower()\n",
    "    # Remove some keyword\n",
    "    elements_to_drop = ['Message-ID:', 'Date:', 'From:', 'To:', 'Subject:', 'Cc:', 'Mime-Version:',\n",
    "     'Content-Type:', 'Content-Transfer-Encoding:', 'Bcc:', 'X-From:', 'X-To:', 'X-cc:', 'X-bcc:',\n",
    "     'X-Folder:', 'X-Origin:', 'X-FileName:', 'cc', '\\t', '--', 'Sent', ' --', '-', '/', '\\n', 'Re:', 'FW:']\n",
    "    for element in elements_to_drop:\n",
    "        email = email.replace(element, '')\n",
    "\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "463840b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emails_df_m_cleaned = emails_df_m_cleaned.loc[emails_df_m[name_col_email].notna()]\n",
    "# emails_df_m_cleaned[name_col_email] = emails_df_m_cleaned[name_col_email].apply(clean_email)\n",
    "\n",
    "emails_df_all_cleaned = emails_df_all.loc[emails_df_all[\"body\"].notna()]\n",
    "emails_df_all_cleaned[\"body\"] = emails_df_all_cleaned[\"body\"].apply(clean_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096987b",
   "metadata": {},
   "source": [
    "## Stopwords removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddea17e",
   "metadata": {},
   "source": [
    "Removing English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e152622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(email):\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    email = email.split()\n",
    "    filtered_sentence = \"\"\n",
    "\n",
    "    for w in email: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence = filtered_sentence + w +\" \"\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d345bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned[\"body\"] = emails_df_all_cleaned[\"body\"].apply(stopword_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d4230",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6708c",
   "metadata": {},
   "source": [
    "Transforming string into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ce4114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned[\"body\"] = emails_df_all_cleaned[\"body\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c25d48",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f733a68",
   "metadata": {},
   "source": [
    "Replacing each word by its root (ex: 'Working' ==> 'Work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "622e3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(email):\n",
    "    \n",
    "    # 1 - Lemmating the verbs\n",
    "    verb_lemmatized = [                  \n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in email   \n",
    "    ]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [                 \n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in verb_lemmatized\n",
    "    ]\n",
    "    \n",
    "    return noun_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6503a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned[\"body\"] = emails_df_all_cleaned[\"body\"].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e0389",
   "metadata": {},
   "source": [
    "Removing empty message contents after preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc61296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned = emails_df_all_cleaned[emails_df_all_cleaned[\"body\"].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6ae43",
   "metadata": {},
   "source": [
    "Converting list messages into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "988c3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned[\"body\"] = emails_df_all_cleaned[\"body\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae9086",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "78546614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6114"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_email_num = random.randint(0,len(emails_df_all_cleaned))\n",
    "random_email_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccda62d",
   "metadata": {},
   "source": [
    "### Before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "557ff6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for taking me in last night.  Sorry about being drunk and stinky.  \\nMy cab, that we called at 6:10, showed up at 7:02.  I was so pissed.  '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_all.loc[random_email_num,\"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329a061",
   "metadata": {},
   "source": [
    "### After cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2f980d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank take last night sorry drink stinky cab call show piss'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_all_cleaned.loc[random_email_num,\"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe280b",
   "metadata": {},
   "source": [
    "## Export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50c1e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df_all_cleaned.to_csv(\"emails_df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97b223",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b7120",
   "metadata": {},
   "source": [
    "### Evaluating a model based on the 1700 emails labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d293a4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.87      0.75       175\n",
      "         2.0       0.00      0.00      0.00        11\n",
      "         3.0       0.00      0.00      0.00        17\n",
      "         4.0       0.64      0.73      0.68        85\n",
      "         5.0       1.00      0.09      0.17        11\n",
      "         6.0       0.58      0.21      0.30        34\n",
      "         7.0       0.00      0.00      0.00         4\n",
      "         8.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.65       341\n",
      "   macro avg       0.36      0.24      0.24       341\n",
      "weighted avg       0.59      0.65      0.59       341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/felix/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/felix/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier # for Semi-Supervised learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# oversample = SMOTE()\n",
    "\n",
    "\n",
    "\n",
    "# Considering only labeled emails\n",
    "emails_df_all_cleaned_train = emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]!=-1]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails_df_all_cleaned_train[\"body\"], emails_df_all_cleaned_train[\"category\"], test_size=0.2)\n",
    "\n",
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.7)\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# X_train_counts, y_train = oversample.fit_resample(X_train_counts, y_train)\n",
    "\n",
    "# Model\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "# recall_df = pd.DataFrame({\"recall_score\": recall.round(3)}, index=range(1,9))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, clf.predict(X_test_counts)))\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "586b1f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18782981</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17189699</td>\n",
       "      <td>any morning between 10 and 11:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1115198</td>\n",
       "      <td>Paula,\\n\\n 35 million is fine\\n\\nPhillip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10523086</td>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4449575</td>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               body\n",
       "0  18782981                          Here is our forecast\\n\\n \n",
       "1  17189699                   any morning between 10 and 11:30\n",
       "2   1115198           Paula,\\n\\n 35 million is fine\\n\\nPhillip\n",
       "3  10523086  ---------------------- Forwarded by Phillip K ...\n",
       "4   4449575  ---------------------- Forwarded by Phillip K ..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_unlabeled = emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]==-1][\"body\"]\n",
    "emails_unlabeled_ID = list(emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]==-1][\"ID\"])\n",
    "emails_unlabeled_vec = vectorizer.transform(emails_unlabeled)\n",
    "\n",
    "\n",
    "y_pred_proba = clf.predict_proba(emails_unlabeled_vec)\n",
    "y_pred = clf.predict(emails_unlabeled_vec)\n",
    "\n",
    "name_col_cat = [\"cat_\" + str(i) for i in range(1,9)]\n",
    "y_pred_proba_df = pd.DataFrame(y_pred_proba, columns = name_col_cat).reset_index(drop=True)\n",
    "X_y_pred = pd.DataFrame({\"ID\":emails_unlabeled_ID,\n",
    "            \"body_clean\" : emails_unlabeled,\n",
    "            \"category_pred\" : y_pred}).reset_index(drop=True)\n",
    "pred_df = pd.concat([X_y_pred, y_pred_proba_df], axis=1)\n",
    "\n",
    "threshold = 0.8\n",
    "pred_df[\"proba_cat\"] = pred_df[name_col_cat].max(axis=1)\n",
    "pred_df[\"keep_cat_pred\"] = pred_df[\"proba_cat\"].apply(lambda x: True if x> threshold else False)\n",
    "new_emails_labeled = pred_df[(pred_df[\"category_pred\"].isin([1,4,5,6])) & (pred_df[\"keep_cat_pred\"])][[\"ID\",\"body_clean\"]]\n",
    "new_emails_labeled_raw = pd.DataFrame(emails_df_all.loc[emails_df_all[\"ID\"].isin(new_emails_labeled[\"ID\"]),[\"ID\",\"body\"]]).reset_index(drop=True)\n",
    "new_emails_labeled_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "64be3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emails_labeled_raw.to_csv(\"new_emails_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f55e6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(pred_df[\"proba_cat\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32376c46",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Labelling emails based on initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eacbe2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b8d9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train-test split on the whole dataset, with labeled and non labeled emails\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails_df_all_cleaned[\"body\"], \n",
    "                                                    emails_df_all_cleaned[\"category\"], \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# X_train_counts, y_train = oversample.fit_resample(X_train_counts, y_train)\n",
    "\n",
    "\n",
    "# Model\n",
    "clf = SVC(probability=True)\n",
    "\n",
    "# Specify Self-Training model parameters\n",
    "self_training_model = SelfTrainingClassifier(base_estimator=clf, # An estimator object implementing fit and predict_proba.\n",
    "                                             threshold=0.8, # default=0.75, The decision threshold for use with criterion='threshold'. Should be in [0, 1).\n",
    "                                             criterion='threshold', # {‘threshold’, ‘k_best’}, default=’threshold’, The selection criterion used to select which labels to add to the training set. If 'threshold', pseudo-labels with prediction probabilities above threshold are added to the dataset. If 'k_best', the k_best pseudo-labels with highest prediction probabilities are added to the dataset.\n",
    "                                             #k_best=50, # default=10, The amount of samples to add in each iteration. Only used when criterion='k_best'.\n",
    "                                             max_iter=10, # default=10, Maximum number of iterations allowed. Should be greater than or equal to 0. If it is None, the classifier will continue to predict labels until no new pseudo-labels are added, or all unlabeled samples have been labeled.\n",
    "                                             verbose=True # default=False, Verbosity prints some information after each iteration\n",
    "                                            )\n",
    "# Fit the model\n",
    "clf_ST = self_training_model.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85d010",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "########## Step 3 - Model Evaluation ########## \n",
    "print('')\n",
    "print('---------- Self Training Model - Summary ----------')\n",
    "print('Base Estimator: ', clf_ST.base_estimator_)\n",
    "print('Classes: ', clf_ST.classes_)\n",
    "print('Transduction Labels: ', clf_ST.transduction_)\n",
    "#print('Iteration When Sample Was Labeled: ', clf_ST.labeled_iter_)\n",
    "print('Number of Features: ', clf_ST.n_features_in_)\n",
    "# print('Feature Names: ', clf_ST.feature_names_in_)\n",
    "\n",
    "print('Number of Iterations: ', clf_ST.n_iter_)\n",
    "print('Termination Condition: ', clf_ST.termination_condition_)\n",
    "print('')\n",
    "\n",
    "print('---------- Self Training Model - Evaluation on Test Data ----------')\n",
    "accuracy_score_ST = clf_ST.score(X_test_counts, y_test)\n",
    "print('Accuracy Score: ', accuracy_score_ST)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_test, clf_ST.predict(X_test_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbd02a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d12d045",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer,TFBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d59bb6ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original email:  please respond kevinscott steve draft contact list promise still typo clean get send draft morning ready circulation list make people know trust large exclude sit pubic official case give organization several useful contact similar knowledge list one person give call convenience discus great detail kevin kevin scott key contact draftdoc\n",
      "Tokenized:  ['please', 'respond', 'kevin', '##sco', '##tt', 'steve', 'draft', 'contact', 'list', 'promise', 'still', 'ty', '##po', 'clean', 'get', 'send', 'draft', 'morning', 'ready', 'circulation', 'list', 'make', 'people', 'know', 'trust', 'large', 'exclude', 'sit', 'pub', '##ic', 'official', 'case', 'give', 'organization', 'several', 'useful', 'contact', 'similar', 'knowledge', 'list', 'one', 'person', 'give', 'call', 'convenience', 'discus', 'great', 'detail', 'kevin', 'kevin', 'scott', 'key', 'contact', 'draft', '##do', '##c']\n",
      "Token IDs : [3531, 6869, 4901, 9363, 4779, 3889, 4433, 3967, 2862, 4872, 2145, 5939, 6873, 4550, 2131, 4604, 4433, 2851, 3201, 9141, 2862, 2191, 2111, 2113, 3404, 2312, 23329, 4133, 9047, 2594, 2880, 2553, 2507, 3029, 2195, 6179, 3967, 2714, 3716, 2862, 2028, 2711, 2507, 2655, 15106, 26047, 2307, 6987, 4901, 4901, 3660, 3145, 3967, 4433, 3527, 2278]\n"
     ]
    }
   ],
   "source": [
    "# Import tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Original sentence\n",
    "random_email_num = random.randint(0,len(emails_df_all_cleaned))\n",
    "random_email = emails_df_all_cleaned.loc[random_email_num,\"body\"] \n",
    "print(\"Original email: \", random_email)\n",
    "\n",
    "# Sentence in tokens\n",
    "print(\"Tokenized: \",tokenizer.tokenize(random_email))\n",
    "\n",
    "# Sentence in token ids\n",
    "print(\"Token IDs :\", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(random_email)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12268c63",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emails_df_all_cleaned_train[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c6b695e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Considering only labeled emails\n",
    "emails_df_all_cleaned_train = emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]!=-1]\n",
    "\n",
    "y = tf.keras.utils.to_categorical(emails_df_all_cleaned_train[\"category\"].values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails_df_all_cleaned_train[\"body\"], \n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bcde3ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output'])\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad2c333d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.4078 - accuracy: 0.4749 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_620/1648577726.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m               metrics = METRICS)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m model_fit = model.fit(X_train, \n\u001b[0m\u001b[1;32m     16\u001b[0m                       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1692\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                         )\n\u001b[0;32m-> 1694\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1695\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         ):\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    950\u001b[0m               args, kwds))\n\u001b[1;32m    951\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(   # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    953\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m           self._concrete_variable_creation_fn.captured_inputs)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "]\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "\n",
    "model_fit = model.fit(X_train, \n",
    "                      y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      batch_size=32,\n",
    "                      validation_data = (X_test, y_test),\n",
    "                      callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9933702",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ydshieh/bert-base-uncased-yelp-polarity were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ydshieh/bert-base-uncased-yelp-polarity.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ydshieh/bert-base-uncased-yelp-polarity\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"ydshieh/bert-base-uncased-yelp-polarity\")\n",
    "\n",
    "# model.add(layers.Dense(15, activation='relu'))\n",
    "# model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Considering only labeled emails\n",
    "emails_df_all_cleaned_train = emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]!=-1]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails_df_all_cleaned_train[\"body\"], emails_df_all_cleaned_train[\"category\"], test_size=0.2)\n",
    "\n",
    "# tokenizer\n",
    "X_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "X_test = tokenizer(\n",
    "    text=X_test.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "input_ids = X_train['input_ids']\n",
    "attention_mask = X_train['attention_mask']\n",
    "\n",
    "# model.fit(X_train_counts, y_train, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "60935a93",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ydshieh/bert-base-uncased-yelp-polarity were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ydshieh/bert-base-uncased-yelp-polarity.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TFBertForSequenceClassification' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_620/450905952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ydshieh/bert-base-uncased-yelp-polarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# /!\\ Must correspond to the task at hand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFBertForSequenceClassification' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ydshieh/bert-base-uncased-yelp-polarity\")\n",
    "# Considering only labeled emails\n",
    "emails_df_all_cleaned_train = emails_df_all_cleaned[emails_df_all_cleaned[\"category\"]!=-1]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails_df_all_cleaned_train[\"body\"], emails_df_all_cleaned_train[\"category\"], test_size=0.2)\n",
    "\n",
    "# tokenizer\n",
    "X_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "X_test = tokenizer(\n",
    "    text=X_test.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"ydshieh/bert-base-uncased-yelp-polarity\")\n",
    "\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax')) # /!\\ Must correspond to the task at hand\n",
    "\n",
    "# STEP 2: OPTIMIZATION METHODS\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# SETP 3: DATA AND FITTING METHODS\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba97dccd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"global_max_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_620/3794459805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"global_max_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "max_len = 70\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = model(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(8,activation = 'softmax')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "# Set loss and metrics\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('accuracy'),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54885a1b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Emails labeled by API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff69fc7b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emails_api = pd.read_csv(\"../../raw_data/emails_sliced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7d3431b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_api.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3d0b1a1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-04 20:51:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>re</td>\n",
       "      <td>traveling to have a business meeting takes the...</td>\n",
       "      <td>[{'category_name': '/Travel &amp; Transportation/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-10-23 13:13:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>randy can you send me a schedule of the salary...</td>\n",
       "      <td>[{'category_name': '/Computers &amp; Electronics/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-08-22 14:44:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>david.l.johnson@enron.com', 'john.shafer@enron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>please cc the following distribution list with...</td>\n",
       "      <td>[{'category_name': '/Arts &amp; Entertainment/TV &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000-10-17 09:26:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>mark.scott@enron.com</td>\n",
       "      <td>re high speed internet access</td>\n",
       "      <td>login pallen pw ke davis i dont think these ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000-10-16 13:44:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>zimam@enron.com</td>\n",
       "      <td>fw fixed forward or other collar floor gas pri...</td>\n",
       "      <td>forwarded by phillip k allenhouect on        ...</td>\n",
       "      <td>[{'category_name': '/Business &amp; Industrial/Ene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Date                     From  \\\n",
       "0           0  2001-05-04 20:51:00  phillip.allen@enron.com   \n",
       "1           1  2000-10-23 13:13:00  phillip.allen@enron.com   \n",
       "2           2  2000-08-22 14:44:00  phillip.allen@enron.com   \n",
       "3           3  2000-10-17 09:26:00  phillip.allen@enron.com   \n",
       "4           4  2000-10-16 13:44:00  phillip.allen@enron.com   \n",
       "\n",
       "                                                  To  \\\n",
       "0                            john.lavorato@enron.com   \n",
       "1                              randall.gay@enron.com   \n",
       "2  david.l.johnson@enron.com', 'john.shafer@enron...   \n",
       "3                               mark.scott@enron.com   \n",
       "4                                    zimam@enron.com   \n",
       "\n",
       "                                             Subject  \\\n",
       "0                                                 re   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                      re high speed internet access   \n",
       "4  fw fixed forward or other collar floor gas pri...   \n",
       "\n",
       "                                             content  \\\n",
       "0  traveling to have a business meeting takes the...   \n",
       "1  randy can you send me a schedule of the salary...   \n",
       "2  please cc the following distribution list with...   \n",
       "3    login pallen pw ke davis i dont think these ...   \n",
       "4   forwarded by phillip k allenhouect on        ...   \n",
       "\n",
       "                                            category  \n",
       "0  [{'category_name': '/Travel & Transportation/S...  \n",
       "1  [{'category_name': '/Computers & Electronics/S...  \n",
       "2  [{'category_name': '/Arts & Entertainment/TV &...  \n",
       "3                                                 []  \n",
       "4  [{'category_name': '/Business & Industrial/Ene...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "787b3907",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3021"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_email = random.randint(1,len(emails_api))\n",
    "random_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f4be44d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " '{',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'g',\n",
       " 'o',\n",
       " 'r',\n",
       " 'y',\n",
       " '_',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " '/',\n",
       " 'F',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " '/',\n",
       " 'I',\n",
       " 'n',\n",
       " 'v',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " '/',\n",
       " 'O',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '0',\n",
       " '.',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '8',\n",
       " '1',\n",
       " '5',\n",
       " '8',\n",
       " '3',\n",
       " '3',\n",
       " '0',\n",
       " '9',\n",
       " '1',\n",
       " '7',\n",
       " '4',\n",
       " '}',\n",
       " ',',\n",
       " ' ',\n",
       " '{',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'g',\n",
       " 'o',\n",
       " 'r',\n",
       " 'y',\n",
       " '_',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " '/',\n",
       " 'L',\n",
       " 'a',\n",
       " 'w',\n",
       " ' ',\n",
       " '&',\n",
       " ' ',\n",
       " 'G',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'n',\n",
       " 'm',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " '/',\n",
       " 'P',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'S',\n",
       " 'a',\n",
       " 'f',\n",
       " 'e',\n",
       " 't',\n",
       " 'y',\n",
       " '/',\n",
       " 'C',\n",
       " 'r',\n",
       " 'i',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " '&',\n",
       " ' ',\n",
       " 'J',\n",
       " 'u',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '0',\n",
       " '.',\n",
       " '2',\n",
       " '0',\n",
       " '8',\n",
       " '3',\n",
       " '4',\n",
       " '9',\n",
       " '5',\n",
       " '8',\n",
       " '5',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '2',\n",
       " '1',\n",
       " '}',\n",
       " ',',\n",
       " ' ',\n",
       " '{',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'g',\n",
       " 'o',\n",
       " 'r',\n",
       " 'y',\n",
       " '_',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " '/',\n",
       " 'F',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " '/',\n",
       " 'I',\n",
       " 'n',\n",
       " 'v',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " '/',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " '&',\n",
       " ' ',\n",
       " 'F',\n",
       " 'u',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'T',\n",
       " 'r',\n",
       " 'a',\n",
       " 'd',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '0',\n",
       " '.',\n",
       " '1',\n",
       " '9',\n",
       " '2',\n",
       " '4',\n",
       " '6',\n",
       " '1',\n",
       " '0',\n",
       " '8',\n",
       " '8',\n",
       " '2',\n",
       " '9',\n",
       " '9',\n",
       " '7',\n",
       " '5',\n",
       " '1',\n",
       " '2',\n",
       " '8',\n",
       " '}',\n",
       " ',',\n",
       " ' ',\n",
       " '{',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'g',\n",
       " 'o',\n",
       " 'r',\n",
       " 'y',\n",
       " '_',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " '/',\n",
       " 'N',\n",
       " 'e',\n",
       " 'w',\n",
       " 's',\n",
       " '/',\n",
       " 'B',\n",
       " 'u',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " ' ',\n",
       " 'N',\n",
       " 'e',\n",
       " 'w',\n",
       " 's',\n",
       " '/',\n",
       " 'F',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'M',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " 'e',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'N',\n",
       " 'e',\n",
       " 'w',\n",
       " 's',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '0',\n",
       " '.',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '0',\n",
       " '3',\n",
       " '9',\n",
       " '7',\n",
       " '7',\n",
       " '0',\n",
       " '5',\n",
       " '4',\n",
       " '3',\n",
       " '5',\n",
       " '7',\n",
       " '5',\n",
       " '2',\n",
       " '9',\n",
       " '}',\n",
       " ']']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"\".join(emails_api.loc[random_email,\"category\"])\n",
    "\n",
    "# list(\"\".join(emails_api.loc[random_email,\"category\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "93ea9a9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' forwarded by john arnoldhouect on        pm  jennifer burns        pm to phillip k allenhouect john arnoldhouect michael w bradleyhouect jennifer fraserhouect mike grigsbyhouect adam grosshouect rogers herndonhouect john j lavoratocorpenron kevin mcgowancorpenron vince j kaminskihouect john l nowlanhouect kevin m prestohouect fletcher j sturmhouect hunter s shivelyhouect bill whitenaenron cc jeffrey a shankmanhouect gary hickersonhouect subject please note that the date for the  st meeting is january   as mentioned during the fourth quarter gary and i would like to begin regular meetings of our traders roundtable the ideas generated from this group should be longer term trading opportunities for enron covering the markets we manage in addition this forum will provide for cross commodity education insight into many areas of enrons businesses and promote aggressive ideas each week well summarize commodity trading activity and provide an open forum for discussion your input is valuable and weve limited this group to our most experienced traders and would appreciate regular participation our first meeting will be tuesday january   at   pm in eb '"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_api.loc[random_email,\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f73d262c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_897/3179580249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails_api\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_897/3179580249.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails_api\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "emails_api[\"category\"].apply(lambda x: x[0][\"category_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7753d9c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0938\n",
       "[{'category_name': '/Business & Industrial/Energy & Utilities/Oil & Gas', 'confidence': 0.5607556104660034}, {'category_name': '/Finance/Investing/Commodities & Futures Trading', 'confidence': 0.4104222059249878}, {'category_name': '/News/Business News/Financial Markets News', 'confidence': 0.26257482171058655}]                                                                                                                                                                  0.0030\n",
       "[{'category_name': '/Online Communities/Social Networks', 'confidence': 0.1728571206331253}]                                                                                                                                                                                                                                                                                                                                                                                               0.0024\n",
       "[{'category_name': '/Real Estate/Property Development', 'confidence': 0.18342076241970062}, {'category_name': '/Real Estate/Other', 'confidence': 0.1411825716495514}, {'category_name': '/News/Business News/Other', 'confidence': 0.10715575516223907}, {'category_name': '/Real Estate/Real Estate Listings/Residential Sales', 'confidence': 0.10664357990026474}, {'category_name': '/Business & Industrial/Construction & Maintenance/Other', 'confidence': 0.10295967757701874}]    0.0024\n",
       "[{'category_name': '/News/Business News/Financial Markets News', 'confidence': 0.5522624254226685}, {'category_name': '/Finance/Investing/Stocks & Bonds', 'confidence': 0.4272659718990326}, {'category_name': '/Finance/Investing/Other', 'confidence': 0.196648508310318}]                                                                                                                                                                                                              0.0022\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...  \n",
       "[{'category_name': '/People & Society/Religion & Belief', 'confidence': 0.6230995655059814}, {'category_name': '/Jobs & Education/Education/Primary & Secondary Schooling (K-12)', 'confidence': 0.10676996409893036}]                                                                                                                                                                                                                                                                     0.0002\n",
       "[{'category_name': '/Business & Industrial/Energy & Utilities/Oil & Gas', 'confidence': 0.46232154965400696}, {'category_name': '/Internet & Telecom/Email & Messaging/Other', 'confidence': 0.1624460369348526}]                                                                                                                                                                                                                                                                          0.0002\n",
       "[{'category_name': '/Business & Industrial/Energy & Utilities/Oil & Gas', 'confidence': 0.42021334171295166}, {'category_name': '/Internet & Telecom/Email & Messaging/Other', 'confidence': 0.17709454894065857}]                                                                                                                                                                                                                                                                         0.0002\n",
       "[{'category_name': '/Law & Government/Public Safety/Crime & Justice', 'confidence': 0.547978937625885}, {'category_name': '/News/Business News/Company News', 'confidence': 0.24899274110794067}]                                                                                                                                                                                                                                                                                          0.0002\n",
       "[{'category_name': '/Online Communities/Social Networks', 'confidence': 0.16690535843372345}]                                                                                                                                                                                                                                                                                                                                                                                              0.0002\n",
       "Name: category, Length: 2537, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_api[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df3e52",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
